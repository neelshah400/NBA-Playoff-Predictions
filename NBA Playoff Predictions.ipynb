{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center>\n",
        "    <h1>NBA Playoff Predictions</h1>\n",
        "    <h3>Neel Shah</h3>\n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Table of contents**<a id='toc0_'></a>    \n",
        "1. [Introduction](#toc1_)    \n",
        "1.1. [Background Information](#toc1_1_)    \n",
        "1.2. [Objective](#toc1_2_)    \n",
        "1.3. [Configuration](#toc1_3_)    \n",
        "2. [Data Collection](#toc2_)    \n",
        "2.1. [Data Sources](#toc2_1_)    \n",
        "2.2. [Scraping Data](#toc2_2_)    \n",
        "3. [Data Processing](#toc3_)    \n",
        "3.1. [Cleaning Data](#toc3_1_)    \n",
        "3.1.1. [Renaming a Single Column](#toc3_1_1_)    \n",
        "3.1.2. [Renaming All Columns](#toc3_1_2_)    \n",
        "3.1.3. [Cleaning a `CSV` File](#toc3_1_3_)    \n",
        "3.2. [Merging Data](#toc3_2_)    \n",
        "4. [Exploratory Data Analysis & Visualization](#toc4_)    \n",
        "5. [Modeling: Analysis, Hypothesis Testing, & Machine Learning](#toc5_)    \n",
        "6. [Interpretation: Insight & Policy Decision](#toc6_)    \n",
        "\n",
        "<!-- vscode-jupyter-toc-config\n",
        "\tnumbering=true\n",
        "\tanchor=true\n",
        "\tflat=true\n",
        "\tminLevel=1\n",
        "\tmaxLevel=6\n",
        "\t/vscode-jupyter-toc-config -->\n",
        "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. <a id='toc1_'></a>[Introduction](#toc0_)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's start off by providing some background information about this topic, defining the objectives of this project, and configuring some things.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.1. <a id='toc1_1_'></a>[Background Information](#toc0_)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The [National Basketball Association (NBA)][NBA] is a professional basketball league in the United States. There are [$30$ teams][NBA teams] in the league, divided evenly into $2$ conferences: the Eastern Conference and the Western Conference.\n",
        "\n",
        "In the regular season, each team plays $82$ games. [NBA regular season standings][NBA standings] are determined by teams' win-loss records within their conferences.\n",
        "\n",
        "The top $8$ teams from each conference advance to the playoffs. In the event of a tie in the standings, there is a [tie-breaking procedure][NBA tie-breaking procedure] used to determine playoff seeding.\n",
        "\n",
        "Starting in the $2019\\text{-}20$ season, the NBA [added a play-in tournament][Bleacher Report play-in tournament] to give the $9^\\text{th}$ and $10^\\text{th}$ place teams in each conference the opportunity to earn a spot in the playoffs. It works as follows:\n",
        "\n",
        "- The $7^\\text{th}$ and $8^\\text{th}$ place teams play a game to determine the $7^\\text{th}$ seed. The winner advances to the playoffs.\n",
        "- The $9^\\text{th}$ and $10^\\text{th}$ place teams play an elimination game. The loser is eliminated.\n",
        "- The loser of the $7/8$ game and the winner of the $9/10$ game play an elimination game to determine the $8^\\text{th}$ seed. The winner advances to the playoffs; the loser is eliminated.\n",
        "\n",
        "Once the final playoff seeding is determined, each team plays an opponent in a best-of-$7$ series. The first to win $4$ games advances to the next round. The first round is followed by the conference semifinals, then the conference finals, then the finals. The team that wins the NBA Finals in the NBA Champion.\n",
        "\n",
        "The matchups for each round are determined using a traditional bracket structure, shown below:\n",
        "\n",
        "![NBA Playoff Bracket](nba-playoff-bracket.png \"NBA Playoff Bracket\")\n",
        "\n",
        "[NBA]: https://www.nba.com/\n",
        "[NBA teams]: https://www.nba.com/teams\n",
        "[NBA standings]: https://www.nba.com/standings\n",
        "[NBA tie-breaking procedure]: https://ak-static-int.nba.com/wp-content/uploads/sites/2/2017/06/NBA_Tiebreaker_Procedures.pdf\n",
        "[Bleacher Report play-in tournament]: https://bleacherreport.com/articles/10031906-adam-silver-envisions-nba-play-in-tournament-becoming-a-fixture-in-this-league\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.2. <a id='toc1_2_'></a>[Objective](#toc0_)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We want to perform some analysis to see if we can identify factors underlying teams' level of success in the playoffs. Our ultimate goal will be to predict the outcome of the NBA playoffs using data from the regular season.\n",
        "\n",
        "Can we accurately predict how many playoff games a team will win?\n",
        "\n",
        "With this informalikely, we could determine if a team is likely to:\n",
        "\n",
        "- Make the conference semifinals (i.e. win at least $4$ playoff games)\n",
        "- Make the conference finals (i.e. win at least $8$ playoff games)\n",
        "- Make the finals (i.e. win at least $12$ playoff games)\n",
        "- Win the championship (i.e. win $16$ playoff games)\n",
        "\n",
        "These are some of the questions we want to answer as we go through the full data science pipeline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.3. <a id='toc1_3_'></a>[Configuration](#toc0_)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll start by importing the [Python][Python] libraries necessary for this project and configuring some things.\n",
        "\n",
        "[Python]: https://www.python.org/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "import time\n",
        "from pathlib import Path\n",
        "import itertools\n",
        "import requests\n",
        "from bs4 import BeautifulSoup, Comment, MarkupResemblesLocatorWarning\n",
        "import pandas as pd\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning, module=\"bs4\")\n",
        "\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36\"\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. <a id='toc2_'></a>[Data Collection](#toc0_)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we need to collect data that we can use in our analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1. <a id='toc2_1_'></a>[Data Sources](#toc0_)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will will scrape data from [Basketball Reference][Basketball Reference], a site that provides historical basketball data.\n",
        "\n",
        "We will use data from the $2002\\text{-}03$ season ([when the NBA switched to the current playoff format, where every series is best-of-$7$][NBA playoffs history]) to the $2022\\text{-}23$ season (the current season). For each season, we will scrape the following information:\n",
        "\n",
        "- Per Game Stats from Season Summary page\n",
        "- Advanced Stats from Season Summary page\n",
        "- Expanded Standings from Standings page\n",
        "- Advanced Stats from Playoffs Summary page\n",
        "\n",
        "For convenience, we will define a function called `pages_to_scrape`. Given a season, it will return a dictionary which maps the URL of the page we will be scraping to the list of information about each table we will be scraping from that page.\n",
        "\n",
        "Each element in the list will be in the form of a dictionary with $2$ items:\n",
        "\n",
        "- The `id` of the `HTML` `table` element we will be scraping from the page\n",
        "- The `path` where we will be storing the table as a `CSV`\n",
        "\n",
        "[Basketball Reference]: https://www.basketball-reference.com/\n",
        "[NBA playoffs history]: https://www.nba.com/magic/history-no-1-vs-no-8-nba-playoffs-20200810\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pages_to_scrape(season):\n",
        "    return {\n",
        "        f\"https://www.basketball-reference.com/leagues/NBA_{season}.html\": [\n",
        "            {\n",
        "                \"id\": \"per_game-team\",\n",
        "                \"path\": f\"data/raw/{season}/regular_season/per_game_stats.csv\",\n",
        "            },\n",
        "            {\n",
        "                \"id\": \"advanced-team\",\n",
        "                \"path\": f\"data/raw/{season}/regular_season/advanced_stats.csv\",\n",
        "            },\n",
        "        ],\n",
        "        f\"https://www.basketball-reference.com/leagues/NBA_{season}_standings.html\": [\n",
        "            {\n",
        "                \"id\": \"expanded_standings\",\n",
        "                \"path\": f\"data/raw/{season}/regular_season/standings.csv\",\n",
        "            }\n",
        "        ],\n",
        "        f\"https://www.basketball-reference.com/playoffs/NBA_{season}.html\": [\n",
        "            {\n",
        "                \"id\": \"advanced-team\",\n",
        "                \"path\": f\"data/raw/{season}/playoffs/advanced_stats.csv\",\n",
        "            }\n",
        "        ],\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2. <a id='toc2_2_'></a>[Scraping Data](#toc0_)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To scrape the data from each page, we will do the following:\n",
        "\n",
        "- Perform an `HTTP` `GET` request to the appropriate URL using the [Requests][Requests] library.\n",
        "- Parse the webpage using [Beautiful Soup][Beautiful Soup].\n",
        "- Find the `HTML` `table` with the appropriate `id`.\n",
        "- Read the parsed `HTML` `table` into a `DataFrame` using [pandas][pandas].\n",
        "- Ensure that the appropriate `path` exists in the filesystem using [pathlib][pathlib].\n",
        "- Write the `DataFrame` to a `CSV` file at the appropriate `path` using [pandas][pandas].\n",
        "\n",
        "In our approach, there are a few issues that we have to address as well:\n",
        "\n",
        "- To save time, if the `CSV` files for a page already exist, we will not re-scrape the page.\n",
        "- It appears that some of the `table` elements are hidden inside of `HTML` comments, so we have to look there if a `table` can't be found normally.\n",
        "- To avoid hitting rate limits (from making too many requests in a given time period), we have to add a $10$ second `sleep` between each `HTTP` `GET` request using the [time][time] library.\n",
        "\n",
        "[Requests]: https://requests.readthedocs.io/en/latest/\n",
        "[Beautiful Soup]: https://beautiful-soup-4.readthedocs.io/en/latest/\n",
        "[pandas]: https://pandas.pydata.org/\n",
        "[pathlib]: https://docs.python.org/3/library/pathlib.html\n",
        "[time]: https://docs.python.org/3/library/time.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [],
      "source": [
        "seasons = list(range(2003, 2023 + 1))\n",
        "\n",
        "for season in seasons:\n",
        "\n",
        "    pages = pages_to_scrape(season)\n",
        "\n",
        "    for url, infoList in pages.items():\n",
        "\n",
        "        if all([Path(info[\"path\"]).exists() for info in infoList]):\n",
        "            continue\n",
        "\n",
        "        page = requests.get(url, headers=headers)\n",
        "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "\n",
        "        for info in infoList:\n",
        "\n",
        "            if Path(info[\"path\"]).exists():\n",
        "                continue\n",
        "\n",
        "            table = soup.find(\"table\", id=info[\"id\"])\n",
        "            if table is None:\n",
        "                for comment in soup.find_all(\n",
        "                    string=lambda text: isinstance(text, Comment)\n",
        "                ):\n",
        "                    comment_soup = BeautifulSoup(comment, \"html.parser\")\n",
        "                    table = comment_soup.find(\"table\", id=info[\"id\"])\n",
        "                    if table is not None:\n",
        "                        break\n",
        "\n",
        "            df = pd.read_html(str(table))[0]\n",
        "            Path(info[\"path\"]).parent.mkdir(parents=True, exist_ok=True)\n",
        "            df.to_csv(info[\"path\"], index=False)\n",
        "\n",
        "        time.sleep(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. <a id='toc3_'></a>[Data Processing](#toc0_)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have collected all the data, we need to process it and make it suitable for analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.1. <a id='toc3_1_'></a>[Cleaning Data](#toc0_)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first step is to figure out how we will be cleaning all the data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1.1. <a id='toc3_1_1_'></a>[Renaming a Single Column](#toc0_)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, let's define a function called `rename_column`. It will take in a column name and return a column name that has been modified to provide more consistency.\n",
        "\n",
        "The renaming rules are as follows:\n",
        "\n",
        "- If the column name contains `Unnamed`, then we will replace it with a blank string.\n",
        "- If the column name is `Rk`, then we will replace it with `Rank`.\n",
        "- If the column name is `Tm`, then we will replace it with `Team`.\n",
        "- If the column name is `Offense Four Factors` (which is the name for a group of $4$ different columns), then we will replace it with a blank string. This way, the sub-columns will be assumed to be referring to the team's statistics on offense.\n",
        "- If the column name is `Defense Four Factors` (which is the name for a group of $4$ different columns), then we will replace it with `Opp`. This way, the sub-columns will be assumed to be referring to the opponent's statistics on offense (the team's statistics on defense).\n",
        "- Otherwise, we will return the original name.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rename_column(name):\n",
        "    if \"Unnamed\" in name:\n",
        "        return \"\"\n",
        "    elif name == \"Rk\":\n",
        "        return \"Rank\"\n",
        "    elif name == \"Tm\":\n",
        "        return \"Team\"\n",
        "    elif name == \"Offense Four Factors\":\n",
        "        return \"\"\n",
        "    elif name == \"Defense Four Factors\":\n",
        "        return \"Opp\"\n",
        "    else:\n",
        "        return name\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1.2. <a id='toc3_1_2_'></a>[Renaming All Columns](#toc0_)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's define a function called `rename_columns`. It takes in a `DataFrame` and a list of the header rows.\n",
        "\n",
        "It works as follows:\n",
        "\n",
        "- If there is a single header row, then it renames each column by calling `rename_column`.\n",
        "- If there are multiple header rows, then it renames both names for each column by calling `rename_column` and combines them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rename_columns(df, header):\n",
        "    if len(header) == 1:\n",
        "        df.columns = [rename_column(i) for i in df.columns]\n",
        "    else:\n",
        "        df.columns = [f\"{rename_column(i)}{rename_column(j)}\" for i, j in df.columns]\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1.3. <a id='toc3_1_3_'></a>[Cleaning a `CSV` File](#toc0_)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's create a dictionary called `files_to_clean` with information about the `CSV` files we need to clean. It will map the filename to a dictionary with $2$ items:\n",
        "\n",
        "- The `header` of the `CSV` file (an array of the row indices for the header)\n",
        "- The `columns` of the `CSV` file that we want to keep for now (after they have been renamed using the `rename_columns` function above)\n",
        "- The `column_mappings`, which map old column names to new column names (for renaming purposes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [],
      "source": [
        "files_to_clean = {\n",
        "    \"regular_season/per_game_stats.csv\": {\n",
        "        \"header\": [0],\n",
        "        \"columns\": [\n",
        "            \"Team\",\n",
        "            \"G\",\n",
        "            \"MP\",\n",
        "            \"FG\",\n",
        "            \"FGA\",\n",
        "            \"FG%\",\n",
        "            \"3P\",\n",
        "            \"3PA\",\n",
        "            \"3P%\",\n",
        "            \"2P\",\n",
        "            \"2PA\",\n",
        "            \"2P%\",\n",
        "            \"FT\",\n",
        "            \"FTA\",\n",
        "            \"FT%\",\n",
        "            \"ORB\",\n",
        "            \"DRB\",\n",
        "            \"TRB\",\n",
        "            \"AST\",\n",
        "            \"STL\",\n",
        "            \"BLK\",\n",
        "            \"TOV\",\n",
        "            \"PF\",\n",
        "            \"PTS\",\n",
        "        ],\n",
        "        \"column_mappings\": {},\n",
        "    },\n",
        "    \"regular_season/advanced_stats.csv\": {\n",
        "        \"header\": [0, 1],\n",
        "        \"columns\": [\n",
        "            \"Team\",\n",
        "            \"Age\",\n",
        "            \"W\",\n",
        "            \"L\",\n",
        "            \"PW\",\n",
        "            \"PL\",\n",
        "            \"MOV\",\n",
        "            \"SOS\",\n",
        "            \"SRS\",\n",
        "            \"ORtg\",\n",
        "            \"DRtg\",\n",
        "            \"NRtg\",\n",
        "            \"Pace\",\n",
        "            \"FTr\",\n",
        "            \"3PAr\",\n",
        "            \"TS%\",\n",
        "            \"eFG%\",\n",
        "            \"TOV%\",\n",
        "            \"ORB%\",\n",
        "            \"FT/FGA\",\n",
        "            \"OppeFG%\",\n",
        "            \"OppTOV%\",\n",
        "            \"OppDRB%\",\n",
        "            \"OppFT/FGA\",\n",
        "        ],\n",
        "        \"column_mappings\": {\"OppDRB%\": \"DRB%\"},\n",
        "    },\n",
        "    \"regular_season/standings.csv\": {\n",
        "        \"header\": [0, 1],\n",
        "        \"columns\": [\"Rank\", \"Team\", \"Overall\", \"PlaceHome\", \"PlaceRoad\"],\n",
        "        \"column_mappings\": {\n",
        "            \"Overall\": \"OverallRecord\",\n",
        "            \"PlaceHome\": \"HomeRecord\",\n",
        "            \"PlaceRoad\": \"RoadRecord\",\n",
        "        },\n",
        "    },\n",
        "    \"playoffs/advanced_stats.csv\": {\n",
        "        \"header\": [0, 1],\n",
        "        \"columns\": [\"Rank\", \"Team\", \"W\", \"L\"],\n",
        "        \"column_mappings\": {\"Rank\": \"PlayoffRank\", \"W\": \"PlayoffW\", \"L\": \"PlayoffL\"},\n",
        "    },\n",
        "}\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's define a function called `clean_csv`. Given the path to a `CSV` file, it will return a `DataFrame` with a cleaned version of the data from the `CSV` file.\n",
        "\n",
        "To clean a file, we do the following:\n",
        "\n",
        "- Using the `files_to_clean` dictionary, obtain the information needed to clean the `CSV` file at the specified path.\n",
        "- Read the `CSV` file at the specified `path` into a `DataFrame` using [pandas][pandas].\n",
        "- Do an initial renaming of columns by calling the `rename_columns` function.\n",
        "- Keep only the specified columns of the `DataFrame`.\n",
        "- Rename the remaining columns using the specified column mappings.\n",
        "- Remove any rows where the `Team` is `League Average` (since this is an aggregate of all the rows in the `DataFrame`, and we have no use for it).\n",
        "- Remove the `*` character for any values in the `Team` column (since it is used to indicate if a team made the playoffs, but we already have that data).\n",
        "\n",
        "[pandas]: https://pandas.pydata.org/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_csv(path):\n",
        "    name = f\"{Path(path).parents[0].name}/{Path(path).name}\"\n",
        "    info = files_to_clean[name]\n",
        "    df = pd.read_csv(path, header=info[\"header\"])\n",
        "    rename_columns(df, info[\"header\"])\n",
        "    df = df[info[\"columns\"]]\n",
        "    df = df.rename(columns=info[\"column_mappings\"])\n",
        "    df = df[df[\"Team\"] != \"League Average\"]\n",
        "    df[\"Team\"] = df[\"Team\"].str.replace(\"*\", \"\", regex=False)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.2. <a id='toc3_2_'></a>[Merging Data](#toc0_)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we need to merge all the cleaned data into a single `DataFrame`.\n",
        "\n",
        "For each season, we will do the following:\n",
        "\n",
        "- Clean the $4$ `CSV` files for the season using the `clean_csv` function.\n",
        "- Merge the $4$ `DataFrame`s for the season on the `Team` column using an outer join in [pandas][pandas].\n",
        "- Add a `Season` column to the beginning of the `DataFrame` and fill all of the rows with the same season value.\n",
        "\n",
        "Then, we concatenate the `DataFrame`s for each season into a single `DataFrame`.\n",
        "\n",
        "[pandas]: https://pandas.pydata.org/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.DataFrame()\n",
        "\n",
        "for season in seasons:\n",
        "\n",
        "    season_data = None\n",
        "\n",
        "    infoList = list(itertools.chain(*pages_to_scrape(season).values()))\n",
        "    pathList = [info[\"path\"] for info in infoList]\n",
        "\n",
        "    for index, path in enumerate(pathList):\n",
        "        df = clean_csv(path)\n",
        "        if index == 0:\n",
        "            season_data = df\n",
        "        else:\n",
        "            season_data = season_data.merge(df, on=\"Team\", how=\"outer\")\n",
        "\n",
        "    season_data.insert(0, \"Season\", season)\n",
        "\n",
        "    data = pd.concat(objs=[data, season_data])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we can look at the merged data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 630 entries, 0 to 29\n",
            "Data columns (total 55 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Season         630 non-null    int64  \n",
            " 1   Team           630 non-null    object \n",
            " 2   G              628 non-null    float64\n",
            " 3   MP             628 non-null    float64\n",
            " 4   FG             628 non-null    float64\n",
            " 5   FGA            628 non-null    float64\n",
            " 6   FG%            628 non-null    float64\n",
            " 7   3P             628 non-null    float64\n",
            " 8   3PA            628 non-null    float64\n",
            " 9   3P%            628 non-null    float64\n",
            " 10  2P             628 non-null    float64\n",
            " 11  2PA            628 non-null    float64\n",
            " 12  2P%            628 non-null    float64\n",
            " 13  FT             628 non-null    float64\n",
            " 14  FTA            628 non-null    float64\n",
            " 15  FT%            628 non-null    float64\n",
            " 16  ORB            628 non-null    float64\n",
            " 17  DRB            628 non-null    float64\n",
            " 18  TRB            628 non-null    float64\n",
            " 19  AST            628 non-null    float64\n",
            " 20  STL            628 non-null    float64\n",
            " 21  BLK            628 non-null    float64\n",
            " 22  TOV            628 non-null    float64\n",
            " 23  PF             628 non-null    float64\n",
            " 24  PTS            628 non-null    float64\n",
            " 25  Age            628 non-null    float64\n",
            " 26  W              628 non-null    float64\n",
            " 27  L              628 non-null    float64\n",
            " 28  PW             628 non-null    float64\n",
            " 29  PL             628 non-null    float64\n",
            " 30  MOV            628 non-null    float64\n",
            " 31  SOS            628 non-null    float64\n",
            " 32  SRS            628 non-null    float64\n",
            " 33  ORtg           628 non-null    float64\n",
            " 34  DRtg           628 non-null    float64\n",
            " 35  NRtg           628 non-null    float64\n",
            " 36  Pace           628 non-null    float64\n",
            " 37  FTr            628 non-null    float64\n",
            " 38  3PAr           628 non-null    float64\n",
            " 39  TS%            628 non-null    float64\n",
            " 40  eFG%           628 non-null    float64\n",
            " 41  TOV%           628 non-null    float64\n",
            " 42  ORB%           628 non-null    float64\n",
            " 43  FT/FGA         628 non-null    float64\n",
            " 44  OppeFG%        628 non-null    float64\n",
            " 45  OppTOV%        628 non-null    float64\n",
            " 46  DRB%           628 non-null    float64\n",
            " 47  OppFT/FGA      628 non-null    float64\n",
            " 48  Rank           628 non-null    float64\n",
            " 49  OverallRecord  628 non-null    object \n",
            " 50  HomeRecord     628 non-null    object \n",
            " 51  RoadRecord     628 non-null    object \n",
            " 52  PlayoffRank    340 non-null    float64\n",
            " 53  PlayoffW       340 non-null    float64\n",
            " 54  PlayoffL       340 non-null    float64\n",
            "dtypes: float64(50), int64(1), object(4)\n",
            "memory usage: 275.6+ KB\n"
          ]
        }
      ],
      "source": [
        "data.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Season</th>\n",
              "      <th>Team</th>\n",
              "      <th>G</th>\n",
              "      <th>MP</th>\n",
              "      <th>FG</th>\n",
              "      <th>FGA</th>\n",
              "      <th>FG%</th>\n",
              "      <th>3P</th>\n",
              "      <th>3PA</th>\n",
              "      <th>3P%</th>\n",
              "      <th>...</th>\n",
              "      <th>OppTOV%</th>\n",
              "      <th>DRB%</th>\n",
              "      <th>OppFT/FGA</th>\n",
              "      <th>Rank</th>\n",
              "      <th>OverallRecord</th>\n",
              "      <th>HomeRecord</th>\n",
              "      <th>RoadRecord</th>\n",
              "      <th>PlayoffRank</th>\n",
              "      <th>PlayoffW</th>\n",
              "      <th>PlayoffL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2003</td>\n",
              "      <td>Dallas Mavericks</td>\n",
              "      <td>82.0</td>\n",
              "      <td>241.2</td>\n",
              "      <td>38.5</td>\n",
              "      <td>85.1</td>\n",
              "      <td>0.453</td>\n",
              "      <td>7.8</td>\n",
              "      <td>20.3</td>\n",
              "      <td>0.381</td>\n",
              "      <td>...</td>\n",
              "      <td>14.8</td>\n",
              "      <td>70.9</td>\n",
              "      <td>0.221</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60-22</td>\n",
              "      <td>33-8</td>\n",
              "      <td>27-14</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2003</td>\n",
              "      <td>Golden State Warriors</td>\n",
              "      <td>82.0</td>\n",
              "      <td>240.9</td>\n",
              "      <td>37.3</td>\n",
              "      <td>84.6</td>\n",
              "      <td>0.441</td>\n",
              "      <td>5.2</td>\n",
              "      <td>15.1</td>\n",
              "      <td>0.344</td>\n",
              "      <td>...</td>\n",
              "      <td>12.2</td>\n",
              "      <td>67.9</td>\n",
              "      <td>0.220</td>\n",
              "      <td>19.0</td>\n",
              "      <td>38-44</td>\n",
              "      <td>24-17</td>\n",
              "      <td>14-27</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2003</td>\n",
              "      <td>Sacramento Kings</td>\n",
              "      <td>82.0</td>\n",
              "      <td>241.8</td>\n",
              "      <td>39.5</td>\n",
              "      <td>85.2</td>\n",
              "      <td>0.464</td>\n",
              "      <td>6.0</td>\n",
              "      <td>15.7</td>\n",
              "      <td>0.381</td>\n",
              "      <td>...</td>\n",
              "      <td>13.6</td>\n",
              "      <td>70.6</td>\n",
              "      <td>0.204</td>\n",
              "      <td>3.0</td>\n",
              "      <td>59-23</td>\n",
              "      <td>35-6</td>\n",
              "      <td>24-17</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2003</td>\n",
              "      <td>Los Angeles Lakers</td>\n",
              "      <td>82.0</td>\n",
              "      <td>243.0</td>\n",
              "      <td>37.7</td>\n",
              "      <td>83.6</td>\n",
              "      <td>0.451</td>\n",
              "      <td>5.9</td>\n",
              "      <td>16.7</td>\n",
              "      <td>0.356</td>\n",
              "      <td>...</td>\n",
              "      <td>13.4</td>\n",
              "      <td>72.7</td>\n",
              "      <td>0.241</td>\n",
              "      <td>6.0</td>\n",
              "      <td>50-32</td>\n",
              "      <td>31-10</td>\n",
              "      <td>19-22</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2003</td>\n",
              "      <td>Milwaukee Bucks</td>\n",
              "      <td>82.0</td>\n",
              "      <td>242.7</td>\n",
              "      <td>37.1</td>\n",
              "      <td>81.3</td>\n",
              "      <td>0.457</td>\n",
              "      <td>7.1</td>\n",
              "      <td>18.6</td>\n",
              "      <td>0.383</td>\n",
              "      <td>...</td>\n",
              "      <td>13.5</td>\n",
              "      <td>69.9</td>\n",
              "      <td>0.237</td>\n",
              "      <td>16.0</td>\n",
              "      <td>42-40</td>\n",
              "      <td>25-16</td>\n",
              "      <td>17-24</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2023</td>\n",
              "      <td>Orlando Magic</td>\n",
              "      <td>82.0</td>\n",
              "      <td>241.2</td>\n",
              "      <td>40.5</td>\n",
              "      <td>86.3</td>\n",
              "      <td>0.470</td>\n",
              "      <td>10.8</td>\n",
              "      <td>31.1</td>\n",
              "      <td>0.346</td>\n",
              "      <td>...</td>\n",
              "      <td>13.1</td>\n",
              "      <td>77.7</td>\n",
              "      <td>0.211</td>\n",
              "      <td>25.0</td>\n",
              "      <td>34-48</td>\n",
              "      <td>20-21</td>\n",
              "      <td>14-27</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2023</td>\n",
              "      <td>Charlotte Hornets</td>\n",
              "      <td>82.0</td>\n",
              "      <td>241.8</td>\n",
              "      <td>41.3</td>\n",
              "      <td>90.4</td>\n",
              "      <td>0.457</td>\n",
              "      <td>10.7</td>\n",
              "      <td>32.5</td>\n",
              "      <td>0.330</td>\n",
              "      <td>...</td>\n",
              "      <td>12.5</td>\n",
              "      <td>75.5</td>\n",
              "      <td>0.211</td>\n",
              "      <td>27.0</td>\n",
              "      <td>27-55</td>\n",
              "      <td>13-28</td>\n",
              "      <td>14-27</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2023</td>\n",
              "      <td>Houston Rockets</td>\n",
              "      <td>82.0</td>\n",
              "      <td>240.9</td>\n",
              "      <td>40.6</td>\n",
              "      <td>88.9</td>\n",
              "      <td>0.457</td>\n",
              "      <td>10.4</td>\n",
              "      <td>31.9</td>\n",
              "      <td>0.327</td>\n",
              "      <td>...</td>\n",
              "      <td>11.8</td>\n",
              "      <td>75.8</td>\n",
              "      <td>0.218</td>\n",
              "      <td>28.0</td>\n",
              "      <td>22-60</td>\n",
              "      <td>14-27</td>\n",
              "      <td>8-33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2023</td>\n",
              "      <td>Detroit Pistons</td>\n",
              "      <td>82.0</td>\n",
              "      <td>241.5</td>\n",
              "      <td>39.6</td>\n",
              "      <td>87.1</td>\n",
              "      <td>0.454</td>\n",
              "      <td>11.4</td>\n",
              "      <td>32.4</td>\n",
              "      <td>0.351</td>\n",
              "      <td>...</td>\n",
              "      <td>11.9</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.231</td>\n",
              "      <td>30.0</td>\n",
              "      <td>17-65</td>\n",
              "      <td>9-32</td>\n",
              "      <td>8-33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2023</td>\n",
              "      <td>Miami Heat</td>\n",
              "      <td>82.0</td>\n",
              "      <td>241.5</td>\n",
              "      <td>39.2</td>\n",
              "      <td>85.3</td>\n",
              "      <td>0.460</td>\n",
              "      <td>12.0</td>\n",
              "      <td>34.8</td>\n",
              "      <td>0.344</td>\n",
              "      <td>...</td>\n",
              "      <td>14.5</td>\n",
              "      <td>77.7</td>\n",
              "      <td>0.198</td>\n",
              "      <td>13.0</td>\n",
              "      <td>44-38</td>\n",
              "      <td>27-14</td>\n",
              "      <td>17-24</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>630 rows Ã— 55 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Season                   Team     G     MP    FG   FGA    FG%    3P   3PA  \\\n",
              "0     2003       Dallas Mavericks  82.0  241.2  38.5  85.1  0.453   7.8  20.3   \n",
              "1     2003  Golden State Warriors  82.0  240.9  37.3  84.6  0.441   5.2  15.1   \n",
              "2     2003       Sacramento Kings  82.0  241.8  39.5  85.2  0.464   6.0  15.7   \n",
              "3     2003     Los Angeles Lakers  82.0  243.0  37.7  83.6  0.451   5.9  16.7   \n",
              "4     2003        Milwaukee Bucks  82.0  242.7  37.1  81.3  0.457   7.1  18.6   \n",
              "..     ...                    ...   ...    ...   ...   ...    ...   ...   ...   \n",
              "25    2023          Orlando Magic  82.0  241.2  40.5  86.3  0.470  10.8  31.1   \n",
              "26    2023      Charlotte Hornets  82.0  241.8  41.3  90.4  0.457  10.7  32.5   \n",
              "27    2023        Houston Rockets  82.0  240.9  40.6  88.9  0.457  10.4  31.9   \n",
              "28    2023        Detroit Pistons  82.0  241.5  39.6  87.1  0.454  11.4  32.4   \n",
              "29    2023             Miami Heat  82.0  241.5  39.2  85.3  0.460  12.0  34.8   \n",
              "\n",
              "      3P%  ...  OppTOV%  DRB%  OppFT/FGA  Rank  OverallRecord  HomeRecord  \\\n",
              "0   0.381  ...     14.8  70.9      0.221   1.0          60-22        33-8   \n",
              "1   0.344  ...     12.2  67.9      0.220  19.0          38-44       24-17   \n",
              "2   0.381  ...     13.6  70.6      0.204   3.0          59-23        35-6   \n",
              "3   0.356  ...     13.4  72.7      0.241   6.0          50-32       31-10   \n",
              "4   0.383  ...     13.5  69.9      0.237  16.0          42-40       25-16   \n",
              "..    ...  ...      ...   ...        ...   ...            ...         ...   \n",
              "25  0.346  ...     13.1  77.7      0.211  25.0          34-48       20-21   \n",
              "26  0.330  ...     12.5  75.5      0.211  27.0          27-55       13-28   \n",
              "27  0.327  ...     11.8  75.8      0.218  28.0          22-60       14-27   \n",
              "28  0.351  ...     11.9  74.0      0.231  30.0          17-65        9-32   \n",
              "29  0.344  ...     14.5  77.7      0.198  13.0          44-38       27-14   \n",
              "\n",
              "    RoadRecord  PlayoffRank  PlayoffW  PlayoffL  \n",
              "0        27-14          8.0      10.0      10.0  \n",
              "1        14-27          NaN       NaN       NaN  \n",
              "2        24-17          3.0       7.0       5.0  \n",
              "3        19-22          7.0       6.0       6.0  \n",
              "4        17-24         11.0       2.0       4.0  \n",
              "..         ...          ...       ...       ...  \n",
              "25       14-27          NaN       NaN       NaN  \n",
              "26       14-27          NaN       NaN       NaN  \n",
              "27        8-33          NaN       NaN       NaN  \n",
              "28        8-33          NaN       NaN       NaN  \n",
              "29       17-24          4.0       3.0       1.0  \n",
              "\n",
              "[630 rows x 55 columns]"
            ]
          },
          "execution_count": 150,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. <a id='toc4_'></a>[Exploratory Data Analysis & Visualization](#toc0_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. <a id='toc5_'></a>[Modeling: Analysis, Hypothesis Testing, & Machine Learning](#toc0_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. <a id='toc6_'></a>[Interpretation: Insight & Policy Decision](#toc0_)\n"
      ]
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "Neel Shah"
      }
    ],
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "title": "NBA Playoff Predictions"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
